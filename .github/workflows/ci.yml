# .github/workflows/ci.yml
name: Sharerapy CI/CD Pipeline

# FEATURE DEVELOPMENT (feature/*, feat/*):
# - Jest Unit Tests + React Testing Library (component validation)
# - ESLint Code Quality + TypeScript checks (code standards)
# - Robot Framework Backend (functional validation)
#
# PULL REQUEST TO DEVELOP:
# - All feature development tests PLUS
# - Cypress E2E Tests (full user workflow validation)
#
# DEVELOP BRANCH INTEGRATION:
# - All PR tests PLUS
# - Robot Framework Staging Tests (environment-specific validation)
# - Build verification for staging deployment
#
# PULL REQUEST TO MAIN (PRODUCTION):
# - All develop tests PLUS
# - Integration Validation (staging + regression Robot Framework tests)
#
# PRODUCTION DEPLOYMENT (main branch):
# - Complete test suite (Unit, ESLint, Backend, E2E, Integration)
# - Build verification + Vercel auto-deployment monitoring
# - Live production health checks (https://sharerapy.vercel.app/)

on:
  push:
    branches: [main, develop, feature/*, feat/*]
  pull_request:
    branches: [main, develop]

jobs:
  # CI - Run Tests (Feature): Jest Unit Tests and React Testing Library
  jest-tests:
    name: Jest Unit Tests and React Testing Library
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: Install dependencies
        run: npm ci --verbose

      - name: Run Jest unit tests
        run: npm test -- --verbose
        env:
          NODE_ENV: test

      - name: Generate
        run: npm test -- --coverage --passWithNoTests --verbose

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-coverage-reports
          path: coverage/

  # ESLint Code Quality Checks for TypeScript/JavaScript Code
  code-quality:
    name: ESLint Code Quality (TypeScript/JavaScript)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: Install dependencies
        run: npm ci --verbose

      - name: Run linting checks
        run: npm run lint

      - name: Run type checking
        run: npx tsc --noEmit --skipLibCheck --listFiles

  # Robot Framework Tests for Backend Logic
  backend-tests:
    name: Backend Tests (Robot Framework)
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/main' || github.base_ref == 'develop' || github.base_ref == 'main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          npm ci --verbose
          pip install --verbose robotframework
          pip install --verbose robotframework-requests
          pip install --verbose robotframework-databaselibrary
          pip install --verbose -r requirements-test.txt

      - name: Build Next.js application
        run: npm run build
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}

      - name: Start Next.js server
        run: |
          echo "Starting Next.js server for testing..."

          npm start &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV

          # Wait for server to be ready 
          sleep 10

          # Check if server is responding (may return 500 due to Supabase config, but server should be running)
          for i in {1..12}; do
            if curl -s http://localhost:3000 > /dev/null 2>&1; then
              echo "Server is responding"
              break
            elif [ $i -eq 12 ]; then
              echo "Server may not be fully ready, but continuing with tests..."
            else
              echo "Waiting for server... attempt $i/12"
              sleep 5
            fi
          done
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}

      - name: Run Robot Framework tests for all entities
        run: |
          mkdir -p test-results
          if [ -d "tests/robot" ]; then
            # Run tests - failures will fail the pipeline until endpoints are implemented
            robot --outputdir tests/robot/output tests/robot
            echo "All tests passed - functions are properly implemented"
          else
            echo "Robot Framework test directories not found, skipping..."
            echo "Expected: tests/robot/patients/, tests/robot/therapists/, tests/robot/reports/"
            echo "No API tests executed" > test-results/output.xml
          fi
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}

      - name: Stop Next.js server
        if: always()
        run: |
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID 2>/dev/null || true
          fi

      - name: Upload Robot Framework results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: robot-framework-results
          path: test-results/

  # Cypress E2E Tests - Full Regression Suite for PRs and Develop Integration
  e2e-tests:
    name: Cypress E2E Tests (Full Regression Suite)
    runs-on: ubuntu-latest
    needs: [jest-tests, backend-tests]
    if: github.event_name == 'pull_request' || (github.event_name == 'push' && github.ref == 'refs/heads/develop')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: Install dependencies
        run: npm ci --verbose

      - name: Check if Cypress tests exist
        id: cypress-check
        run: |
          if [ -d "cypress/e2e" ] && [ "$(ls -A cypress/e2e 2>/dev/null)" ]; then
            echo "has-tests=true" >> $GITHUB_OUTPUT
            echo "Found Cypress tests - will run with verbose output"
          else
            echo "has-tests=false" >> $GITHUB_OUTPUT
            echo "No Cypress tests found, skipping E2E testing"
          fi

      - name: Run Cypress E2E tests
        if: steps.cypress-check.outputs.has-tests == 'true'
        uses: cypress-io/github-action@v6
        with:
          build: npm run build
          start: npm start
          wait-on: "http://localhost:3000"
          wait-on-timeout: 120
          browser: chrome
          config: baseUrl=http://localhost:3000
        env:
          DEBUG: cypress:*
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_PUBLISHABLE_KEY }}
          NODE_ENV: test

      - name: Skip E2E tests (no test files)
        if: steps.cypress-check.outputs.has-tests == 'false'
        run: |
          echo "Cypress E2E tests skipped - No test files found"
          echo "Add test files to cypress/e2e/ directory to enable E2E testing"

      - name: Upload Cypress screenshots
        if: failure() && steps.cypress-check.outputs.has-tests == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: cypress-screenshots
          path: cypress/screenshots

  # Integration Validation for PRs to Main (Production Safety)
  pr-main-integration-validation:
    name: Integration Validation for Production
    runs-on: ubuntu-latest
    needs: [jest-tests, code-quality, backend-tests, e2e-tests]
    if: github.event_name == 'pull_request' && github.base_ref == 'main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: Install dependencies
        run: |
          npm ci --verbose
          pip install --verbose robotframework
          pip install --verbose robotframework-requests
          pip install --verbose -r requirements-test.txt

      - name: Run integration tests for production readiness
        run: |
          echo "Running integration validation for PR to main..."
          mkdir -p tests/robot
          if [ -f "tests/robot/*.robot" ]; then
            # Run staging and regression tests for production readiness
            robot --loglevel DEBUG --include staging --include regression --outputdir pr-integration-results tests/robot/
            echo "Integration validation completed for production"
          else
            echo "No Robot Framework integration tests found, skipping..."
            mkdir -p pr-integration-results
            echo "No integration tests executed" > pr-integration-results/output.xml
          fi

      - name: Upload PR integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pr-main-integration-results
          path: pr-integration-results/

  # CI - Run Tests (Develop): Re-run Full Regression Suite for Integrated Features
  develop-integration-validation:
    name: Develop Integration - Full Regression Suite
    runs-on: ubuntu-latest
    needs: [jest-tests, code-quality, backend-tests, e2e-tests]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: Install dependencies
        run: |
          npm ci --verbose
          pip install --verbose robotframework
          pip install --verbose robotframework-requests
          pip install --verbose -r requirements-test.txt

      - name: Run staging test suite
        run: |
          mkdir -p tests/robot
          if [ -f "tests/robot/*.robot" ]; then
            # Run staging tests on develop branch
            robot --loglevel DEBUG --include staging --outputdir staging-results tests/robot/
          else
            echo "No Robot Framework staging tests found, skipping..."
            mkdir -p staging-results
            echo "No staging tests executed" > staging-results/output.xml
          fi

      - name: Build verification for staging
        run: |
          echo "Verifying build on develop branch (staging)..."
          npm run build --verbose
          echo "Staging build successful - Ready for integration testing"

      - name: Upload staging test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: staging-test-results
          path: staging-results/

  # CD - Deploy to Production: Production Deployment Pipeline with Full Test Suite
  production-deployment-validation:
    name: Production Deployment Pipeline
    runs-on: ubuntu-latest
    needs: [jest-tests, code-quality, backend-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: "npm"

      - name: Install dependencies
        run: |
          npm ci --verbose
          pip install --verbose robotframework
          pip install --verbose robotframework-requests
          pip install --verbose -r requirements-test.txt

      - name: Run E2E tests for production validation
        run: |
          # Check if Cypress tests exist
          if [ -d "cypress/e2e" ] && [ "$(ls -A cypress/e2e 2>/dev/null)" ]; then
            echo "Running Cypress E2E tests for production validation..."
            npx cypress run --browser chrome --config baseUrl=http://localhost:3000 &
            CYPRESS_PID=$!
            npm run build && npm start &
            SERVER_PID=$!
            
            # Wait for server to be ready
            timeout 120 bash -c 'until curl -f http://localhost:3000; do sleep 2; done'
            
            # Wait for Cypress to complete
            wait $CYPRESS_PID
            CYPRESS_EXIT_CODE=$?
            
            # Clean up
            kill $SERVER_PID 2>/dev/null || true
            
            if [ $CYPRESS_EXIT_CODE -ne 0 ]; then
              echo "❌ E2E tests failed - blocking production deployment"
              exit 1
            fi
            echo "✅ E2E tests passed for production"
          else
            echo "No Cypress tests found - skipping E2E validation"
          fi

      - name: Run regression test suite
        run: |
          mkdir -p tests/robot
          if [ -f "tests/robot/*.robot" ]; then
            # Run critical regression tests on main branch with verbose output
            robot --loglevel DEBUG --include regression --outputdir regression-results tests/robot/
          else
            echo "No Robot Framework regression tests found, skipping..."
            mkdir -p regression-results
            echo "No regression tests executed" > regression-results/output.xml
          fi

      - name: Run integration validation for production
        run: |
          echo "Running integration validation for production deployment..."
          mkdir -p tests/robot
          if [ -f "tests/robot/*.robot" ]; then
            # Run all integration tests (staging + regression)
            robot --loglevel DEBUG --include staging --include regression --outputdir integration-results tests/robot/
            echo "Integration validation completed"
          else
            echo "No Robot Framework integration tests found, skipping..."
            mkdir -p integration-results
            echo "No integration tests executed" > integration-results/output.xml
          fi

      - name: Build verification
        run: |
          echo "Verifying build on main branch with verbose output..."
          npm run build --verbose
          echo "Build successful - Ready for deployment"

      - name: Wait for Vercel deployment
        run: |
          echo "Waiting for Vercel auto-deployment to complete..."
          sleep 60
          echo "Deployment wait period completed"

      - name: Production health check
        run: |
          echo "Performing production health checks..."
          # Basic connectivity test
          curl -f -s -o /dev/null -w "%{http_code}" https://sharerapy.vercel.app/ || exit 1
          echo "Production site is accessible"

          # Check if the site returns 200 OK
          RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" https://sharerapy.vercel.app/)
          if [ "$RESPONSE" -eq 200 ]; then
            echo "Production health check passed (HTTP $RESPONSE)"
          else
            echo "Production health check failed (HTTP $RESPONSE)"
            exit 1
          fi

      - name: Post-deployment validation
        run: |
          echo "Production deployment validation completed successfully"
          echo "Full test suite executed (Unit, ESLint, Backend, E2E, Integration)"
          echo "Live site validated: https://sharerapy.vercel.app/"
          echo "Deployment timestamp: $(date)"

      - name: Upload production test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: production-test-results
          path: |
            regression-results/
            integration-results/
